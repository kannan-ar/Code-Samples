This is an architecture of a sub system which track the sales data from a message broker and event source in an appropriate data store. The application capable to intensively writes data using any load testing tool to mimic the heavy traffic. There should be proper health check and monitoring tool for the api endpoints.

suggestions:

for better performance we can split the write and read database. The write database records all the data related to sales and read databases uses the denormalized form of sales data to improve the performance of read query. The message broker might have a abstract layer with masstransit or so.

Message broker: Kafka
Event source data store: Cassandra
Read projection data store : Elastic search
Load testing tool: NBomber
Orchestration tool: docker compose


Order details for event source:

Order id: guid
Product name: string
Quantity: int
Payment method: string
Shipping address: text
Billing address: text
Product info: text
Amount: numeric
Discounts: numeric
Tax amount: numeric
Subtotal: numeric
Shipping method: text
Currency: string
Cart id: guid
Seller info: string
Created at: datetime
User id: string

Detailed read projection:

Card id: guid
Created at: datetime
User id: string
Payment method: string
Shipping address: text
Billing address: text
Tax amount: numeric
Subtotal: numeric
Shipping method: text
Currency: string
Items: [
  Product name: string
  Quantity: int
  Amount: numeric
  Seller info: string
]

Summary read projection:

Card id: guid
Products: text
Shipping address: text
Billing address: text
Tax amount: numeric
Subtotal: numeric
Shipping method: text
Currency: string

Microservices:

Command API - Produces messages to Kafka, Starts the event sourcing flow
Domain Service (.NET Worker Service) - Handle domain logic, manage actor state with Akka.Net
Projections - Build read models, populate Elasticsearch
Query API - Exposes queries on the read models

High performance event sourcing system have following characteristics:

Distributed nature - Distributed systems can easily scale and load balancing.
Highly scalable - Distributed nature can help on this.
Fault tolerant - In case of failure, the system should easily recover from it.
Monitoring - Proper logging and metrics and essentials to recover from error.
Eventual consistency - It helps system to handle high load
Concurrency - implement concurrency whenever possible
Batch event processing -


1. Configure the kafka with at least once
2. Configure the fetch.min.bytes, fetch.max.wait.ms, max.poll.records, auto.offset.reset = earliest, enable.auto.commit = false parameters for performance.
3. For event sourcing with Kafka, the most effective partition assignment strategy is key-based partitioning combined with the Sticky Assignor
4. Partition-aware consumer groups in Kafka enhance performance in .NET Core applications by enabling parallel message processing and load balancing
5. Consume messages in batches and process parallely using Channels (System.Threading.Channels) or TPL Dataflow to decouple fetch and processing.
6. Offload the write to cassandra into a seperate process with bulk insert.
7. Monitor lag per partition, consumer offsets, processing time, error rate on Kafka and consumers.
8. Implement backpressure by controlling batch size and concurrency limits.
9. Use prometheus and grafana to monitor the pressure on partitions
----------------------------------------------------------------------

Architecture:

1. Command service has api has an endpoint to submit and order created event. The masstransit responsible for add this event to a kafka topic.
2. Domain service has a background service which assign a bounded channel to each partition of kafka. 



